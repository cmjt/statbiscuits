[["index.html", "Collection of #rstats and #biostats worksheets Preface", " Collection of #rstats and #biostats worksheets written by statbiscuits Preface Artwork by @allison_horst A collection of (MWE) worksheets illustrating some fundamental #rstats and #biostats concepts. These sheets are meant as (fun) worked examples; they are not meant as comprehensive teaching materials. The worked examples, alongside the provided data, can be used as optional or extra casestudies to illustrate the concepts and familiarise students with the approaches outwith course materials. Feel free to modify and extend for your own use (Rmarkdown files). "],["animating-acronyms.html", "1 Animating Acronyms 1.1 Data exploration 1.2 Format the data to suit our porposes 1.3 Plotting", " 1 Animating Acronyms Inspired by the paper, Meta-Research: The growth of acronyms in the scientific literature (radio interview here), we'll use gganimate to create an animation of the top twenty acronyms used in the titles of scientific publications 1900--2019 (see similar animation here). If you want download and wrangle to data yourself then feel free to use this R script; however for simplicity we'll download the data we'll need directly from GitHub. data_url &lt;- &quot;https://github.com/cmjt/statbiscuits/raw/master/swots/data/top_twenty.RData&quot; load(url(data_url)) 1.1 Data exploration The R object we've loaded, named top_twenty, is a list of length 30, where each element contains a data.frame for each year with the following variables: pmid, acronyms, nchar, source, Journal.Title, ISSN, eISSN, Year, Volume, Issue, Page, DOI, PMCID, Manuscript.Id, Release.Date. The name of each element in the list indicate the year of publication. names(top_twenty) ## [1] &quot;1990&quot; &quot;1991&quot; &quot;1992&quot; &quot;1993&quot; &quot;1994&quot; &quot;1995&quot; &quot;1996&quot; &quot;1997&quot; &quot;1998&quot; &quot;1999&quot; ## [11] &quot;2000&quot; &quot;2001&quot; &quot;2002&quot; &quot;2003&quot; &quot;2004&quot; &quot;2005&quot; &quot;2006&quot; &quot;2007&quot; &quot;2008&quot; &quot;2009&quot; ## [21] &quot;2010&quot; &quot;2011&quot; &quot;2012&quot; &quot;2013&quot; &quot;2014&quot; &quot;2015&quot; &quot;2016&quot; &quot;2017&quot; &quot;2018&quot; &quot;2019&quot; The column acronyms contains the top-twenty acronym used in the title of a publication in Journal.Title identified by pmid and PMCID. The number of characters in an acronym are given in the nchar column. Other information relating to the published article is given in the other columns. head(top_twenty[[1]]) ## pmid acronyms nchar source Journal.Title ISSN eISSN Year Volume ## 1 1688383 RNA 3 Title J Virol 0022-538X 1098-5514 1990 64 ## 2 1688384 mRNA 4 Title J Virol 0022-538X 1098-5514 1990 64 ## 3 1688384 mRNA 4 Title J Virol 0022-538X 1098-5514 1990 64 ## 4 1688464 RNA 3 Title Mol Cell Biol 0270-7306 1098-5549 1990 10 ## 5 1688465 RNA 3 Title Mol Cell Biol 0270-7306 1098-5549 1990 10 ## 6 1688530 RNA 3 Title EMBO J 0261-4189 1460-2075 1990 9 ## Issue Page DOI PMCID Manuscript.Id Release.Date ## 1 1 222 PMC249091 live ## 2 1 239 PMC249096 live ## 3 1 239 PMC249096 live ## 4 1 184 10.1128/mcb.10.1.184 PMC360726 live ## 5 1 28 10.1128/mcb.10.1.28 PMC360709 live ## 6 1 257 PMC551656 live As you can imagine for the top-twenty acronyms alone there are thousands of observations each year: sapply(top_twenty, nrow) ## 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 ## 3814 3913 3923 4130 4305 4358 4409 4424 4649 4411 4535 4540 4475 ## 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 ## 5196 5754 6324 7303 8610 11823 14540 17129 19374 22391 25060 26968 29226 ## 2016 2017 2018 2019 ## 30040 32890 33776 33779 Let's look at the top-twenty acronyms in 1990: table(top_twenty[[1]]$acronyms) ## ## AIDS AMP ATP cAMP CD3 CD4 CD8 cDNA DNA HIV HLA IgG IL MHC mRNA PCR ## 139 81 155 42 43 126 58 342 1212 230 107 59 83 48 277 68 ## RFLP RNA rRNA tRNA ## 108 465 51 120 1.2 Format the data to suit our porposes A long list probably isn't the best way to summarise these data - We could combine all the elements into one big dataframe (remember we have already have a column specifying year) library(dplyr) df &lt;- bind_rows(top_twenty) head(df) ## pmid acronyms nchar source Journal.Title ISSN eISSN Year Volume ## 1 1688383 RNA 3 Title J Virol 0022-538X 1098-5514 1990 64 ## 2 1688384 mRNA 4 Title J Virol 0022-538X 1098-5514 1990 64 ## 3 1688384 mRNA 4 Title J Virol 0022-538X 1098-5514 1990 64 ## 4 1688464 RNA 3 Title Mol Cell Biol 0270-7306 1098-5549 1990 10 ## 5 1688465 RNA 3 Title Mol Cell Biol 0270-7306 1098-5549 1990 10 ## 6 1688530 RNA 3 Title EMBO J 0261-4189 1460-2075 1990 9 ## Issue Page DOI PMCID Manuscript.Id Release.Date ## 1 1 222 PMC249091 live ## 2 1 239 PMC249096 live ## 3 1 239 PMC249096 live ## 4 1 184 10.1128/mcb.10.1.184 PMC360726 live ## 5 1 28 10.1128/mcb.10.1.28 PMC360709 live ## 6 1 257 PMC551656 live Let's count the acronyms count &lt;- df %&gt;% count(acronyms) head(count) ## acronyms n ## 1 ABC 160 ## 2 ADP 60 ## 3 AIDS 5020 ## 4 AKT 657 ## 5 AMP 377 ## 6 ATP 9302 Not quite what we want, we forgot to group by year... count &lt;- df %&gt;% group_by(Year) %&gt;% count(acronyms) head(count) ## # A tibble: 6 x 3 ## # Groups: Year [1] ## Year acronyms n ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 1990 AIDS 139 ## 2 1990 AMP 81 ## 3 1990 ATP 155 ## 4 1990 cAMP 42 ## 5 1990 CD3 43 ## 6 1990 CD4 126 Now let's sort by the most used by year and rank ranked &lt;- count %&gt;% arrange(Year, -n) %&gt;% mutate(rank = as.factor(1:n())) head(ranked) ## # A tibble: 6 x 4 ## # Groups: Year [1] ## Year acronyms n rank ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;fct&gt; ## 1 1990 DNA 1212 1 ## 2 1990 RNA 465 2 ## 3 1990 cDNA 342 3 ## 4 1990 mRNA 277 4 ## 5 1990 HIV 230 5 ## 6 1990 ATP 155 6 1.3 Plotting Numbers of each acronym by year library(ggplot2) ggplot(ranked, aes(x = Year, y = n, col = acronyms)) + geom_line() Quite a lot going on... What about a bar graph so we can easily compare acronyms? One thing to note is that as we've already &quot;counted&quot; the acronyms then we need to specify stat = &quot;identity&quot; in our call to geom_bar() so that ggplot() knows to use our data as bar heights. Note also that we can flip x = and y = inside aes() to switch the axes. ggplot(ranked, aes(x = n, y = rank, fill = acronyms)) + geom_bar(stat = &quot;identity&quot;) We've forgotten about year what about using facet_wrap()? The colours are awful how about a decent palette (e.g., scale_fill_brewer(palette = &quot;Dark2&quot;))? See others here. The trouble with the &quot;Dark2&quot; palette from RColorBrewer is that it only contains 8 different colours and we need 54! No problem we can simply extend the colour palette using the colorRampPalette() function from ColorBrewer: ## We need 54 colours as there are 54 unique acronyms library(RColorBrewer) n.cols &lt;- 54 mycols &lt;- colorRampPalette(brewer.pal(8, &quot;Dark2&quot;))(n.cols) head(mycols) ## [1] &quot;#1B9E77&quot; &quot;#349567&quot; &quot;#4D8D58&quot; &quot;#668548&quot; &quot;#7F7C39&quot; &quot;#987429&quot; So, we use facet_wrap() to create a multi panel plot (splitting by Year) and scale_fill_manual() to specify our chosen (better) colour palette for the fill aesthetic. ggplot(ranked, aes(x = n, y = rank, fill = acronyms)) + geom_bar(stat = &quot;identity&quot;) + facet_wrap(~Year) + scale_fill_manual(values = mycols) Well there's quite a lot going on there; let's let the axes differ for each year as - not all counts are the same, and - not all acronyms turn up each year. We can use scales = &quot;free&quot; in our facet_wrap() call for this. ggplot(ranked, aes(x = n, y = rank, fill = acronyms)) + geom_bar(stat = &quot;identity&quot;) + facet_wrap(~Year, scales = &quot;free&quot;) + scale_fill_manual(values = mycols) There are a number of issues with this plot; let's sort a few of them out: using geom_text() we'll label each bar by the acronym it represents and left justify this text, hjust = &quot;left&quot; we'll suppress the x- and y-axis labels using xlab(&quot;&quot;) and ylab(&quot;&quot;) (is there good reason to do this?) we'll change the theme to theme_gray(), other options discussed here in addition to the theme we choose we may want to fine tune some other elements so using theme() we'll suppress the y-axis ticks and labels with axis.text.y = element_blank(),axis.ticks.y = element_blank() and scrap the needless legend using legend.position = &quot;none&quot;. Remember we have the acronym labels now! finally, to reverse the order of the factor ranks, 1...20, we use scale_y_discrete() so that 1 is on top plot &lt;- ggplot(ranked, aes(x = n, y = rank, fill = acronyms)) + geom_bar(stat = &quot;identity&quot;) + facet_wrap(~Year, scales = &quot;free&quot;) + scale_fill_manual(values = mycols) + geom_text(aes(label = acronyms), hjust = &quot;left&quot;, col = &quot;darkgrey&quot;) + xlab(&quot;&quot;) + ylab(&quot;&quot;) + theme_gray() + theme(axis.text.y = element_blank(),axis.ticks.y = element_blank(),legend.position = &quot;none&quot;) + scale_y_discrete(limits = rev(levels(ranked$rank))) plot There's still a lot going on! So let's us gganimate to create a racing barchart! It's as simple as adding + transition_time()! Although we do have to use facet_null() to forget the facet_wrap() stuff (for reasons only ggplot2 wizards know). Let's also add a title specifying year using labs(). library(gganimate) anim &lt;- plot + transition_time(Year) + facet_null() + ## we have to forget facet stuff for reasons only ggplot2 wizards know labs(title = &quot;Year: {frame_time}&quot;) anim "],["clusterducks.html", "2 ClusterDucks 2.1 RGB data 2.2 K means clustering", " 2 ClusterDucks In Sydney, the ducks have their own fashion show.... Use the drop-down menu to explore the collection of duck outfits. blue_flowers-1 blue_flowers-2 blue_flowers-3 blue_flowers-4 blue_flowers-5 bridal-1 bridal-2 bridal-3 bridal-4 bridal-5 bridal-6 bridal-7 patterns-1 patterns-2 patterns-3 patterns-4 pink_check-1 pink_check-2 pink_check-3 pink_check-4 red-1 red-2 red-3 red-4 red-5 red-6 wax_jacket-1 wax_jacket-2 wax_jacket-3 All images used here are available here. To read images into R you can use the readJPEG() function from the R package jpeg. Using readJPEG each image is read in as a \\(m*n*3\\) array, where each of the three \\(m*n\\) matricies are the red, green, and blue primary values (R, G, &amp; B values) of each pixel respectivly. 2.1 RGB data For ease, however, we're going to download the RGB data directly from GitHub. data_url &lt;- &quot;https://github.com/cmjt/statbiscuits/raw/master/swots/data/duck_rgbs.RData&quot; load(url(data_url)) Figure 2.1: RGB arrays for the first image (element) of the ducks_rgbs object. The image is of a duck in the 'blue flowers' outfit. Figure 2.2: RGB arrays for the second image (element) of the ducks_rgbs object. The image is of a duck in the 'blue flowers' outfit. The duck_rgbs object is a named list of RGB arrays for each image. There are 29 different images of 6 different outfits. length(duck_rgbs) ## [1] 29 names(duck_rgbs) ## [1] &quot;blue_flowers-1&quot; &quot;blue_flowers-2&quot; &quot;blue_flowers-3&quot; &quot;blue_flowers-4&quot; ## [5] &quot;blue_flowers-5&quot; &quot;bridal-1&quot; &quot;bridal-2&quot; &quot;bridal-3&quot; ## [9] &quot;bridal-4&quot; &quot;bridal-5&quot; &quot;bridal-6&quot; &quot;bridal-7&quot; ## [13] &quot;patterns-1&quot; &quot;patterns-2&quot; &quot;patterns-3&quot; &quot;patterns-4&quot; ## [17] &quot;pink_check-1&quot; &quot;pink_check-2&quot; &quot;pink_check-3&quot; &quot;pink_check-4&quot; ## [21] &quot;red-1&quot; &quot;red-2&quot; &quot;red-3&quot; &quot;red-4&quot; ## [25] &quot;red-5&quot; &quot;red-6&quot; &quot;wax_jacket-1&quot; &quot;wax_jacket-2&quot; ## [29] &quot;wax_jacket-3&quot; Let's summarise each image by the average R, G, and B value respectively. cluster_ducks &lt;- data.frame(attire = stringr::str_match(names(duck_rgbs),&quot;(.*?)-&quot;)[,2], av_red = sapply(duck_rgbs, function(x) mean(c(x[,,1]))), av_green = sapply(duck_rgbs, function(x) mean(c(x[,,2]))), av_blue = sapply(duck_rgbs, function(x) mean(c(x[,,3])))) head(cluster_ducks) ## attire av_red av_green av_blue ## blue_flowers-1 blue_flowers 0.4529505 0.4790429 0.4610547 ## blue_flowers-2 blue_flowers 0.4751319 0.5131624 0.4977116 ## blue_flowers-3 blue_flowers 0.4560981 0.4881459 0.4919892 ## blue_flowers-4 blue_flowers 0.4745254 0.5117347 0.4948642 ## blue_flowers-5 blue_flowers 0.5955183 0.6413420 0.5757063 ## bridal-1 bridal 0.5718594 0.5645125 0.4567448 table(cluster_ducks$attire) ## ## blue_flowers bridal patterns pink_check red wax_jacket ## 5 7 4 4 6 3 library(plotly) ## for 3D interactive plots plot_ly(x = cluster_ducks$av_red, y = cluster_ducks$av_green, z = cluster_ducks$av_blue, type = &quot;scatter3d&quot;, mode = &quot;markers&quot;, color = cluster_ducks$attire) Figure 2.3: 3D scatterplot of the average RGB value per image. Rather than the average R, G, &amp; B let's calculate the proportion of each primary. prop.max &lt;- function(x){ ## matrix of index of max RGB values of x mat_max &lt;- apply(x,c(1,2),which.max) ## table of collapsed values tab &lt;- table(c(mat_max)) ## proportion of red prop_red &lt;- tab[1]/sum(tab) prop_green &lt;- tab[2]/sum(tab) prop_blue &lt;- tab[3]/sum(tab) return(c(prop_red,prop_green,prop_blue)) } ## proportion of r, g, b in each image prop &lt;- do.call(&#39;rbind&#39;,lapply(duck_rgbs,prop.max)) cluster_ducks$prop_red &lt;- prop[,1] cluster_ducks$prop_green &lt;- prop[,2] cluster_ducks$prop_blue &lt;- prop[,3] plot_ly(x = cluster_ducks$prop_red, y = cluster_ducks$prop_green, z = cluster_ducks$prop_blue, type = &quot;scatter3d&quot;, mode = &quot;markers&quot;, color = cluster_ducks$attire) Figure 2.4: 3D scatterplot of the proportion of RGB value per image. 2.2 K means clustering Can we cluster the images based on the calculated measures above? ## library for k-means clustering library(factoextra) ## re format data. We deal only with the numerics info df &lt;- cluster_ducks[,2:7] ## specify rownames as image names rownames(df) &lt;- names(duck_rgbs) distance &lt;- get_dist(df) fviz_dist(distance, gradient = list(low = &quot;#00AFBB&quot;, mid = &quot;white&quot;, high = &quot;#FC4E07&quot;)) So we have an idea there are 6... but is there enough information in the noisy images? Setting nstart = 25 means that R will try 25 different random starting assignments and then select the best results corresponding to the one with the lowest within cluster variation. ## from two clusters to 6 (can we separate out the images?) set.seed(4321) k2 &lt;- kmeans(df, centers = 2, nstart = 25) k3 &lt;- kmeans(df, centers = 3, nstart = 25) k4 &lt;- kmeans(df, centers = 4, nstart = 25) k5 &lt;- kmeans(df, centers = 5, nstart = 25) k6 &lt;- kmeans(df, centers = 6, nstart = 25) The kmeans() function returns a list of components: cluster, integers indicating the cluster to which each observation is allocated centers, a matrix of cluster centers/means totss, the total sum of squares withinss, within-cluster sum of squares, one component per cluster tot.withinss, total within-cluster sum of squares betweenss, between-cluster sum of squares size, number of observations in each cluster k2$tot.withinss ## [1] 2.786543 k3$tot.withinss ## [1] 1.75652 k4$tot.withinss ## [1] 1.193151 k5$tot.withinss ## [1] 0.9316645 k6$tot.withinss ## [1] 0.7281481 barplot(c(k2$tot.withinss,k3$tot.withinss,k4$tot.withinss, k5$tot.withinss,k6$tot.withinss), names = paste(2:6,&quot; clusters&quot;)) p2 &lt;- fviz_cluster(k2, data = df) p3 &lt;- fviz_cluster(k3, data = df) p4 &lt;- fviz_cluster(k4, data = df) p5 &lt;- fviz_cluster(k5, data = df) p6 &lt;- fviz_cluster(k6, data = df) ## for arranging plots library(patchwork) p2/ p3/ p4/ p5/ p6 2.2.1 How many clusters are best? The fviz_nbclust() function in the R package factoextra can be used to compute the three different methods [elbow, silhouette and gap statistic] for any partitioning clustering methods [K-means, K-medoids (PAM), CLARA, HCUT]. # Elbow method fviz_nbclust(df, kmeans, method = &quot;wss&quot;) + labs(subtitle = &quot;Elbow method&quot;) # Silhouette method fviz_nbclust(df, kmeans, method = &quot;silhouette&quot;)+ labs(subtitle = &quot;Silhouette method&quot;) # Gap statistic # recommended value: nboot= 500 for your analysis. set.seed(123) fviz_nbclust(df, kmeans, nstart = 25, method = &quot;gap_stat&quot;, nboot = 50)+ labs(subtitle = &quot;Gap statistic method&quot;) ## Clustering k = 1,2,..., K.max (= 10): .. done ## Bootstrapping, b = 1,2,..., B (= 50) [one &quot;.&quot; per sample]: ## .................................................. 50 "],["eigenfaces.html", "3 Eigenfaces 3.1 Prep for PCA 3.2 Principal Component Analysis (PCA) 3.3 1000 faces", " 3 Eigenfaces So what is an Eigenface? Let's fine out! We follow this blogpost and recreate the approach in R. First off let's get a sample of the data from the statbiscuits repository on GitHub (these data are wrangled versions of those from n0acar's GitHub repository), see here for the raw script I used to download and wrangle the data. data_url &lt;- &quot;https://github.com/cmjt/statbiscuits/raw/master/swots/data/faces.RData&quot; load(url(data_url)) The faces object is a list() with 16 named elements: library(pixmap) ## needed to deal with the data names(faces) ## [1] &quot;Angelina Jolie&quot; &quot;Arnold Schwarzenegger&quot; &quot;Azra Akin&quot; ## [4] &quot;Bill Gates&quot; &quot;Daniel Radcliffe&quot; &quot;David Beckham&quot; ## [7] &quot;Dwayne Johnson&quot; &quot;George W Bush&quot; &quot;Gwyneth Paltrow&quot; ## [10] &quot;Hillary Clinton&quot; &quot;LeBron James&quot; &quot;Marilyn Monroe&quot; ## [13] &quot;Michael Jackson&quot; &quot;Michael Jordan&quot; &quot;Oprah Winfrey&quot; ## [16] &quot;Queen Elizabeth II&quot; Each element is a grey pixmap image of the person named. Let's plot the pixmap images par(mfrow = c(4,4), mar = c(0,0,0,0), oma = c(0,0,0,0)) for(i in 1:length(faces)){ plot(faces[[i]]) legend(&quot;bottom&quot;, bty = &quot;n&quot;, names(faces[i])) } Figure 3.1: Each face in our dataset. 3.1 Prep for PCA Collapse each image into one column of a matrix. ## collapse the grey matrix face_data &lt;- lapply(faces, function(x) c(x@grey)) ## each column is a face face_data &lt;- do.call(&#39;cbind&#39;,face_data) colnames(face_data) &lt;- names(faces) ## have a look at the data matrix head(face_data) ## Angelina Jolie Arnold Schwarzenegger Azra Akin Bill Gates Daniel Radcliffe ## [1,] 0.3921569 0.4274510 0.3019608 0.8235294 0.2000000 ## [2,] 0.3960784 0.4274510 0.2901961 0.8313725 0.2392157 ## [3,] 0.4039216 0.4235294 0.2862745 0.8313725 0.2745098 ## [4,] 0.4039216 0.4274510 0.2745098 0.8313725 0.3058824 ## [5,] 0.4235294 0.4352941 0.2745098 0.8235294 0.3176471 ## [6,] 0.4392157 0.4431373 0.2666667 0.8274510 0.3254902 ## David Beckham Dwayne Johnson George W Bush Gwyneth Paltrow Hillary Clinton ## [1,] 0.3058824 0.2235294 0.5529412 0.7411765 0.2705882 ## [2,] 0.3333333 0.2313725 0.5607843 0.7843137 0.3176471 ## [3,] 0.3921569 0.2274510 0.5490196 0.8117647 0.3686275 ## [4,] 0.4470588 0.2078431 0.5686275 0.8313725 0.4745098 ## [5,] 0.4862745 0.2039216 0.5803922 0.8313725 0.5686275 ## [6,] 0.5254902 0.1960784 0.5450980 0.8352941 0.6470588 ## LeBron James Marilyn Monroe Michael Jackson Michael Jordan Oprah Winfrey ## [1,] 0.5333333 0.08627451 0.1529412 0.3372549 0.1372549 ## [2,] 0.5254902 0.11764706 0.1647059 0.3411765 0.1607843 ## [3,] 0.5333333 0.16470588 0.2078431 0.3411765 0.1686275 ## [4,] 0.5215686 0.17647059 0.2549020 0.3450980 0.1764706 ## [5,] 0.5294118 0.14117647 0.3176471 0.3411765 0.1647059 ## [6,] 0.5490196 0.13333333 0.4039216 0.3137255 0.1960784 ## Queen Elizabeth II ## [1,] 0.1725490 ## [2,] 0.1921569 ## [3,] 0.2078431 ## [4,] 0.2470588 ## [5,] 0.2784314 ## [6,] 0.3254902 3.1.1 Center around mean ## center around mean mean &lt;- apply(face_data, 1, mean) mean_face &lt;- pixmapGrey(mean, 64, 64, bbox = c(0, 0, 64, 64)) plot(mean_face) Figure 3.2: The 'mean' face from the 16 in our dataset. centered &lt;- apply(face_data, 2, function(x) x - mean) ## centered images par(mfrow = c(4,4), mar = c(0,0,0,0), oma = c(0,0,0,0)) for(i in 1:length(faces)){ plot(pixmapGrey(centered[,i], 64, 64, bbox = c(0, 0, 64, 64))) legend(&quot;bottom&quot;, bty = &quot;n&quot;, paste(names(faces[i]), &quot;centered&quot;, sep = &quot; &quot;)) } Figure 3.3: Each face centered (i.e., with the mean face subtracted). 3.2 Principal Component Analysis (PCA) pca &lt;- prcomp(centered) summary(pca) ## Importance of components: ## PC1 PC2 PC3 PC4 PC5 PC6 PC7 ## Standard deviation 0.2824 0.2135 0.15918 0.1511 0.13552 0.12660 0.11789 ## Proportion of Variance 0.2811 0.1605 0.08928 0.0805 0.06471 0.05647 0.04897 ## Cumulative Proportion 0.2811 0.4416 0.53088 0.6114 0.67609 0.73256 0.78153 ## PC8 PC9 PC10 PC11 PC12 PC13 PC14 ## Standard deviation 0.11556 0.10636 0.09315 0.09213 0.08201 0.07425 0.06766 ## Proportion of Variance 0.04705 0.03986 0.03057 0.02990 0.02370 0.01943 0.01613 ## Cumulative Proportion 0.82858 0.86843 0.89901 0.92891 0.95261 0.97204 0.98817 ## PC15 PC16 ## Standard deviation 0.05796 2.689e-16 ## Proportion of Variance 0.01183 0.000e+00 ## Cumulative Proportion 1.00000 1.000e+00 The PCA object, pca, contains the following information: the center point ($center), scaling ($scale), and standard deviation ($sdev) of each principal component, as well as the principal components ($rotation), and the values of each sample in terms of the principal components ($x) ## for a nice biplot library(ggfortify) library(ggplot2) ## using autoplot ## PC1 vs PC2 by default autoplot(pca,loadings = TRUE,loadings.label = TRUE,alpha = 0.1) ## play around with the arguments to see what they control autoplot(pca,x = 3, y = 4,loadings = TRUE,loadings.label = TRUE,alpha = 0.1) 3.2.1 Eigenfaces (Principal Components) ## eigen faces pcs &lt;- pca$x eigenfaces &lt;- apply(pcs,2, function(x) pixmapGrey(x, 64, 64, bbox = c(0, 0, 64, 64))) par(mfrow = c(4,4), mar = c(0,0,0,0), oma = c(0,0,0,0)) for(i in 1:length(eigenfaces)){ plot(eigenfaces[[i]]) legend(&quot;bottom&quot;, bty = &quot;n&quot;, paste(&quot;PC&quot;, i, sep = &quot; &quot;)) } Figure 3.4: Each eigenface (PC1 to PC16). Note how noisy the faces get. 3.2.2 Reconstructing 3.2.2.1 How many coponents should we keep? Each face is a weighted (loadings) combintation of the eigen faces (PCs) above, but how many PCs (eigenfaces) do we keep? ## screeplot screeplot(pca,type = &quot;lines&quot;, pch = 20) str(pca$rotation) ## num [1:16, 1:16] 0.0668 -0.0609 -0.1394 0.2008 0.3148 ... ## - attr(*, &quot;dimnames&quot;)=List of 2 ## ..$ : chr [1:16] &quot;Angelina Jolie&quot; &quot;Arnold Schwarzenegger&quot; &quot;Azra Akin&quot; &quot;Bill Gates&quot; ... ## ..$ : chr [1:16] &quot;PC1&quot; &quot;PC2&quot; &quot;PC3&quot; &quot;PC4&quot; ... ## 2 PCs n_pc &lt;- 2 recon &lt;- pixm &lt;- list() for (i in 1:length(faces)){ recon[[i]] &lt;- rowSums(pca$x[,1:n_pc]%*%pca$rotation[i,1:n_pc]) pixm[[i]] &lt;- pixmapGrey(recon[[i]], 64, 64, bbox = c(0, 0, 64, 64)) } ## 2PC to reconstruct centered imags par(mfrow = c(4,4), mar = c(0,0,0,0), oma = c(0,0,0,0)) for(i in 1:length(pixm)){ plot(pixm[[i]]) legend(&quot;bottom&quot;, bty = &quot;n&quot;, paste(names(faces[i]), &quot;2 PC&quot;, sep = &quot; &quot;)) } ### Hmm OK, what about 5 ## 5 PCs n_pc &lt;- 5 recon &lt;- pixm &lt;- list() for (i in 1:length(faces)){ recon[[i]] &lt;- rowSums(pca$x[,1:n_pc]%*%pca$rotation[i,1:n_pc]) pixm[[i]] &lt;- pixmapGrey(recon[[i]], 64, 64, bbox = c(0, 0, 64, 64)) } ## 5PC to reconstruct centered images par(mfrow = c(4,4), mar = c(0,0,0,0), oma = c(0,0,0,0)) for(i in 1:length(pixm)){ plot(pixm[[i]]) legend(&quot;bottom&quot;, bty = &quot;n&quot;, paste(names(faces[i]), &quot;5 PC&quot;, sep = &quot; &quot;)) } ### Hmm OK, what about 10 ## 10 PCs n_pc &lt;- 10 recon &lt;- pixm &lt;- list() for (i in 1:length(faces)){ recon[[i]] &lt;- rowSums(pca$x[,1:n_pc]%*%pca$rotation[i,1:n_pc]) pixm[[i]] &lt;- pixmapGrey(recon[[i]], 64, 64, bbox = c(0, 0, 64, 64)) } ## 10PC to reconstruct centered images par(mfrow = c(4,4), mar = c(0,0,0,0), oma = c(0,0,0,0)) for(i in 1:length(pixm)){ plot(pixm[[i]]) legend(&quot;bottom&quot;, bty = &quot;n&quot;, paste(names(faces[i]), &quot;10 PC&quot;, sep = &quot; &quot;)) } ## remember this is the centered image, let&#39;s add the &quot;mean face&quot; to reconstruct the original par(mfrow = c(4,4), mar = c(0,0,0,0), oma = c(0,0,0,0)) for(i in 1:length(recon)){ plot(pixmapGrey(recon[[i]] + mean, 64, 64, bbox = c(0, 0, 64, 64))) legend(&quot;bottom&quot;, bty = &quot;n&quot;, paste(names(faces[i]), &quot;10 PC + mean&quot;, sep = &quot; &quot;)) } 3.3 1000 faces Above we use only 16 images, but what if we had many, many, more. Then dimension reduction becomes much more useful. Here is a zipped archive of over 13,000 faces as grey pixmap images, as above. We can download the archive, unzip, and read the files into R: zip &lt;- &quot;http://conradsanderson.id.au/lfwcrop/lfwcrop_grey.zip&quot; temp &lt;- tempfile(fileext = &quot;.zip&quot;) download.file(zip,destfile = temp) tst &lt;- unzip(temp) unlink(temp) all_faces &lt;- list.files(&quot;lfwcrop_grey/faces&quot;,pattern = &quot;.pgm&quot;, full = TRUE) ## read in a random subset of these images ## using set.seed to ensure the following is reproducible (means you will get the same subset) set.seed(6666) choose &lt;- sample(1:length(all_faces), 1000, replace = FALSE) face_set &lt;- lapply(choose, function(x) read.pnm(all_faces[x])) ## name the object accordingly col &lt;- sapply(all_faces[choose], function(x) strsplit(strsplit(x,&quot;faces/&quot;)[[1]][2],&quot;_&quot;)[[1]]) names &lt;- sapply(col, function(y) paste(y[-length(y)], collapse = &quot; &quot;)); names(names) &lt;- NULL head(names) ## if you&#39;ve used the same seed as above this is what you should see ## [1] &quot;Susilo Bambang Yudhoyono&quot; &quot;Brandon Larson&quot; ## [3] &quot;Kurt Warner&quot; &quot;Toshihiko Fukui&quot; ## [5] &quot;Clemente de la Vega&quot; &quot;Harvey Fierstein&quot; names(face_set) &lt;- names Mean face (of the 1000 faces) ## collapse the grey matrix face_data &lt;- lapply(face_set, function(x) c(x@grey)) ## each column is a face face_data &lt;- do.call(&#39;cbind&#39;,face_data) colnames(face_data) &lt;- names(face_set) ## mean face mean &lt;- apply(face_data, 1, mean) mean_face &lt;- pixmapGrey(mean, 64, 64, bbox = c(0, 0, 64, 64)) plot(mean_face) (#fig:collapse and meanface)The 'mean' face from the 1000 in our dataset. SPOOKY PCA centered &lt;- apply(face_data, 2, function(x) x - mean) pca &lt;- prcomp(centered) ## screeplot screeplot(pca,type = &quot;lines&quot;, pch = 20) What does our first eigen face look like? ## eigen faces pcs &lt;- pca$x eigenfaces &lt;- apply(pcs,2, function(x) pixmapGrey(x, 64, 64, bbox = c(0, 0, 64, 64))) plot(eigenfaces[[1]]) legend(&quot;bottom&quot;, bty = &quot;n&quot;, &quot;PC 1&quot;) Figure 3.5: First eigenface (PC1). How many PCs would you keep? Let's try 200 (from a possible 1000) and recreate the first face in our dataset. n_pc &lt;- 200 recon &lt;- rowSums(pca$x[,1:n_pc]%*%pca$rotation[1,1:n_pc]) ## add the &quot;mean face&quot; to reconstruct the original par(mfrow = c(1,2), mar = c(0,0,0,0), oma = c(0,0,0,0)) ## original plot(face_set[[1]]) legend(&quot;bottom&quot;, bty = &quot;n&quot;, paste(names(face_set[1]), &quot;original&quot;, sep = &quot; &quot;)) ## reconstructed plot(pixmapGrey(recon + mean, 64, 64, bbox = c(0, 0, 64, 64))) legend(&quot;bottom&quot;, bty = &quot;n&quot;, paste(names(face_set[1]), &quot;reconstructed&quot;, sep = &quot; &quot;)) "],["seed-art.html", "4 seed aRt 4.1 What is a seed? 4.2 flametree 4.3 Thorns", " 4 seed aRt 4.1 What is a seed? &quot;A random seed (or seed state, or just seed) is a number used to initialize a pseudorandom number generator.&quot; 4.2 flametree Inspired by Danielle Navarro's aRt packages we illustrate, using art, what setting a random seed does. ## use ## devtools::install_github(&quot;djnavarro/flametree&quot;) ## to install library(flametree) To grow the flametree we use the flametree_grow() function which has an argument seed. Using this we can grow any number of unique flametrees! ## R release date = 29 February 2000 ## so set seed = 20000229 flametree &lt;- flametree_grow(seed = 20000229) flametree_plot(tree = flametree) ## The year of lockdowns 2020 flametree &lt;- flametree_grow(seed = 2020) flametree_plot(tree = flametree) 4.2.1 Grow your own tree 4.3 Thorns What about thorn02? ## required packages pkgs &lt;- c(&quot;Rcpp&quot;,&quot;ggplot2&quot;,&quot;ggforce&quot;,&quot;voronise&quot;,&quot;dplyr&quot;,&quot;here&quot;) for(i in 1:length(pkgs)) if(!require(pkgs[i])) install.packages(pkgs[i]) ## This isn&#39;t a package so we source the code files from GitHub ## and create the directory structure the function expects ## .cpp file needed dir.create(&quot;../source&quot;) dir.create(&quot;../image&quot;) download.file(&quot;https://raw.githubusercontent.com/djnavarro/thorn02/master/source/thorn_02.cpp&quot;,destfile = &quot;../source/thorn_02.cpp&quot;) devtools::source_url(&quot;https://raw.githubusercontent.com/djnavarro/thorn02/master/source/thorn_02.R&quot;) The thorn02() function we've just sourced has one argument: seed. ## using the worst password in the world thorn02(seed = 1234) ## glasses of wine I had last night thorn02(seed = 3) ## R release date = 29 February 2000 ## so set seed = 20000229 thorn02(seed = 20000229) "]]
